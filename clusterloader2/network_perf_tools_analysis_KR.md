# 네트워크 성능 테스트 도구(iperf, siege) 분석 보고서

## 1. 개요

본 문서는 `clusterloader2`와 같은 쿠버네티스 성능 테스트 환경에서 사용되는 네트워크 테스트 도구 `iperf`와 `siege`에 대해 설명합니다. 각 도구의 주요 측정 항목, 인수 테스트 관점에서의 사용 목적, 그리고 일반적인 서비스 수준 목표(SLO)를 이해하기 쉽게 정리하는 것을 목표로 합니다.

## 2. iperf: 네트워크 처리량(Throughput) 측정 도구

`iperf`는 두 지점 간의 최대 네트워크 대역폭(throughput)을 측정하기 위한 표준 도구입니다. TCP 및 UDP 트래픽을 생성하여 네트워크 인프라의 순수 성능을 평가하는 데 사용됩니다.

### 가. 주요 측정 항목

- **대역폭 (Bandwidth/Throughput)**: 초당 전송할 수 있는 데이터의 양 (예: Gbps, Mbps). 네트워크가 최대로 처리할 수 있는 트래픽 양을 나타내는 핵심 지표입니다.
- **지터 (Jitter)**: 패킷 도착 시간의 변동성. 실시간 통신(VoIP, 영상 스트리밍) 품질에 중요한 영향을 미칩니다.
- **패킷 손실 (Packet Loss)**: 전송된 패킷 중 유실된 패킷의 비율. 네트워크의 안정성과 신뢰성을 나타냅니다.

### 나. 인수 테스트 관점에서의 사용 목적

1.  **네트워크 인프라 검증**: 클러스터를 구성하는 물리적/가상 네트워크 장비(스위치, 라우터) 및 케이블링이 기대하는 성능(예: 10Gbps, 40Gbps)을 실제로 제공하는지 확인합니다.
2.  **CNI(Container Network Interface) 성능 검증**: 쿠버네티스 클러스터에 설치된 CNI 플러그인(예: Calico, Cilium, Flannel)이 유발하는 오버헤드를 측정하고, CNI가 Pod 간 통신 성능 요구사항을 만족하는지 평가합니다.
3.  **다양한 통신 경로 성능 측정**:
    - **Pod-to-Pod (East-West Traffic)**: 클러스터 내부의 파드 간 통신 성능을 측정하여 마이크로서비스 아키텍처의 기본 통신 성능을 보장합니다.
    - **Pod-to-Service**: ClusterIP, NodePort 등 쿠버네티스 서비스를 경유할 때의 성능 저하를 측정합니다.
    - **Pod-to-External (North-South Traffic)**: 클러스터 외부로 나가는 트래픽의 성능을 측정하여 외부 서비스와의 연동 성능을 확인합니다.

### 다. 일반적인 SLO (Service Level Objective) 목표 예시

- **대역폭**: "Pod 간 TCP 통신 시, 노드의 물리적 네트워크 인터페이스 속도의 90% 이상을 달성해야 한다." (예: 10Gbps NIC에서 9Gbps 이상)
- **패킷 손실**: "10분간의 iperf 테스트 동안 패킷 손실률은 0.01% 미만이어야 한다."
- **지터**: "실시간 서비스용 네트워크에서는 지터가 10ms 이하로 유지되어야 한다."

---

## 3. siege: HTTP 부하 테스트 및 벤치마킹 도구

`siege`는 웹 서버와 애플리케이션의 성능을 측정하기 위한 Layer 7(HTTP/HTTPS) 부하 생성 도구입니다. 지정된 URL에 대해 동시 사용자를 시뮬레이션하여 요청을 보냄으로써, 실제 사용자 부하 상태에서 애플리케이션이 어떻게 동작하는지 평가합니다.

### 가. 주요 측정 항목

- **초당 트랜잭션 수 (Transactions per second)**: 서버가 1초에 처리할 수 있는 HTTP 요청의 수. 서버의 처리 용량을 나타내는 핵심 지표입니다.
- **응답 시간 (Response Time)**: 요청을 보낸 후 응답을 받기까지 걸린 평균 시간. 사용자 경험과 직결되는 중요한 지표입니다.
- **동시 접속자 수 (Concurrency)**: 테스트가 진행되는 동안 동시 연결을 유지한 사용자 수.
- **성공/실패율 (Success/Failure Rate)**: 전체 요청 중 성공(HTTP 2xx) 또는 실패(HTTP 4xx, 5xx)한 요청의 비율. 서비스의 안정성을 나타냅니다.

### 나. 인수 테스트 관점에서의 사용 목적

1.  **애플리케이션 성능 검증**: 배포된 웹 애플리케이션(API 서버, 프론트엔드 등)이 목표 동시 사용자 수를 감당할 수 있는지, 응답 시간 요구사항을 만족하는지 확인합니다.
2.  **로드밸런서 및 인그레스(Ingress) 성능 검증**: 쿠버네티스 서비스(LoadBalancer 타입)나 인그레스 컨트롤러를 통해 외부로 노출된 서비스의 성능 한계를 측정하고 병목 지점을 파악합니다.
3.  **오토스케일링(Autoscaling) 기능 검증**: `siege`로 부하를 발생시켜 HPA(Horizontal Pod Autoscaler)가 정상적으로 동작하는지(부하에 따라 Pod 수가 증가하고, 부하가 줄면 다시 감소하는지) 확인하고, 스케일아웃 과정에서 서비스 지연이나 실패가 없는지 검증합니다.

### 다. 일반적인 SLO (Service Level Objective) 목표 예시

- **응답 시간**: "핵심 API인 `/api/v1/data` 엔드포인트의 p99(99th percentile) 응답 시간은 200ms 미만이어야 한다."
- **성공률**: "분당 10,000개의 요청 부하 상태에서, HTTP 5xx 에러 발생률은 0.1% 미만이어야 한다."
- **처리량**: "시스템은 초당 1,000개의 요청(RPS)을 처리할 수 있어야 하며, 이때 평균 응답 시간은 50ms를 초과하지 않아야 한다."

## 4. 요약: iperf vs. siege

| 구분 | iperf | siege |
| :--- | :--- | :--- |
| **OSI 계층** | Layer 4 (TCP/UDP) | Layer 7 (HTTP/HTTPS) |
| **주 목적** | **네트워크 인프라**의 순수 대역폭/품질 측정 | **애플리케이션/서비스**의 응답성 및 처리량 측정 |
| **측정 대상** | CNI, 물리/가상 네트워크 장비 | 웹 서버, API 게이트웨이, 인그레스, 로드밸런서 |
| **관점** | "파이프라인은 얼마나 넓고 깨끗한가?" | "파이프라인을 통과하는 서비스는 얼마나 빠른가?" |
